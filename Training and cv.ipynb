{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from utils.utils import get_file_names, open_files, save_files\n",
    "from utils.model_processing import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fed_rate_month_avg                        float64\n",
       "Fed_rate_spot_EOM                         float64\n",
       "Fed_rate_month_avg_diff                   float64\n",
       "Fed_rate_month_avg_pct_change             float64\n",
       "Fed_rate_month_avg_diff_3_class           float64\n",
       "Fed_rate_month_avg_diff_5_class           float64\n",
       "Fed_rate_month_avg_diff_9_class           float64\n",
       "Fed_rate_month_avg_trend                  float64\n",
       "Date                               datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_eur = False\n",
    "early = False\n",
    "train_test_ratio = 0.7\n",
    "if early:\n",
    "    START_DATE = dt.datetime(1960, 2, 1)\n",
    "elif with_eur:\n",
    "    START_DATE = dt.datetime(2001, 2, 1)\n",
    "else:\n",
    "    START_DATE = dt.datetime(1992, 1, 1)\n",
    "END_DATE = dt.datetime.today() - pd.offsets.MonthEnd(2)\n",
    "TEST_DATE = START_DATE + train_test_ratio * (END_DATE - START_DATE)\n",
    "ROW_SHIFTS = (1, 2, 3, 6, 12)\n",
    "predicted_feature = 'FF_month_avg_diff'\n",
    "\n",
    "path = 'Models/startdate_{:s}_testdate_{:s}/'.format(START_DATE.strftime(\"%Y\"),\n",
    "                                                     TEST_DATE.strftime(\"%Y\")\n",
    "                                                    )\n",
    "file_names = [f + \"_t-\" + \"_\".join([str(i) for i in ROW_SHIFTS]) + \".csv\" for f in [\"X_train\", \"Y_train\", \"X_test\", \"Y_test\"]]\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = open_files(path=path,\n",
    "                                              file_names=file_names\n",
    "                                             ).values()\n",
    "Y_train['Date'] = pd.to_datetime(Y_train['Date'])\n",
    "Y_test['Date'] = pd.to_datetime(Y_test['Date'])\n",
    "Y_test.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predicted feature, model type and related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_cv_params(estimator, params_to_cv=None):\n",
    "    name = estimator.__class__.__name__\n",
    "    if name == \"LinearDiscriminantAnalysis\":\n",
    "        cv_params = {}\n",
    "    elif name == \"LinearRegression\":\n",
    "        cv_params = {}\n",
    "    elif name == \"LogisticRegression\":\n",
    "        cv_params == {}\n",
    "    elif name == \"RandomForestRegressor\" or name == \"RandomForestClassifier\":\n",
    "        cv_params = {\n",
    "            'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],  # Number of trees\n",
    "            'max_features': [1, 'auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "            'max_depth': [int(x) for x in np.linspace(10, 110, num = 6)] + [None],  # maximum depth of a tree\n",
    "            'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at each leaf node\n",
    "        }\n",
    "    elif name == \"GradientBoostingRegressor\" or name == \"GradientBoostingClassifier\":\n",
    "        cv_params = {\n",
    "            'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 110, num = 6)],  # Number of trees\n",
    "            'learning_rate': np.logspace(-3, -1, 3),  # weight of each tree in final estimator\n",
    "            'max_depth': [3, 5, 7],  # maximum depth of a tree\n",
    "            'min_samples_split': np.arange(2, int(np.sqrt(len(X_train.index))), 5),  # min number of obs in node to be considered for a split\n",
    "            'max_features': ['sqrt', 'auto'],  # Number of features to consider at every split\n",
    "            'min_samples_leaf': [1, 2, 3, 4],  # Minimum number of samples required at each leaf node\n",
    "            'subsample': np.linspace(start=0.6, stop=1, num=5),\n",
    "            'ccp_alpha': [0, 1e-4, 1e-2],  # Complexity parameter for tree prunning\n",
    "        }\n",
    "    elif name == \"XGBRegressor\" or name == \"XGBClassifier\":\n",
    "        cv_params = {\n",
    "            'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)],  # Number of trees\n",
    "            'eta': np.logspace(-2, -0.5, 3),  # weight of each tree in final estimator\n",
    "            'max_depth': [3, 6, 10],  # maximum depth of a tree\n",
    "            'min_child_weight': [1, 3, 6, 10],\n",
    "            'subsample': np.linspace(start=0.6, stop=1, num=5),\n",
    "#             'colsample_bytree': [0.3, 0.3, 0.7, 1],\n",
    "            'gamma': [0, 1, 5, 10],\n",
    "        }\n",
    "    else:\n",
    "        print(\"\\n\" + \" No cross-validation params defined for this estimator yet \".center(120, \"-\"))\n",
    "        cv_params = {}\n",
    "    if params_to_cv is not None:\n",
    "        temp = {}\n",
    "        for param in cv_params.keys():\n",
    "            if param in params_to_cv:\n",
    "                temp[param] = cv_params[param]\n",
    "        cv_params = temp\n",
    "    print(\"\\n\" + \" Params to be tested: \".center(120, \"-\"))\n",
    "    [print(key, value) for key, value in cv_params.items()]\n",
    "    n_combi = len(list(itertools.product(*cv_params.values())))\n",
    "    print(\"\\n\" + \" # of possible combinations to be cross-validated: {:d}\".format(n_combi))\n",
    "    return cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_feature = 'Fed_rate_month_avg_diff'\n",
    "# predicted_feature = 'Fed_rate_month_avg_diff_5_class'\n",
    "\n",
    "# Regression\n",
    "# estimator = GradientBoostingRegressor(random_state=SEED)\n",
    "# estimator = RandomForestRegressor(random_state=SEED)\n",
    "estimator = XGBRegressor(random_state = SEED)\n",
    "\n",
    "# Classification\n",
    "# estimator = LinearDiscriminantAnalysis()\n",
    "# estimator = RandomForestClassifier(random_state=SEED)\n",
    "# estimator = GradientBoostingClassifier(random_state=SEED)\n",
    "\n",
    "# params_to_cv = ['max_depth']\n",
    "params_to_cv = ['n_estimators',\n",
    "                'eta',\n",
    "                'max_depth',\n",
    "                'min_child_weight',\n",
    "#                 'subsample',\n",
    "                'gamma'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------- Feature to be predicted: -----------------------------------------------\n",
      "Fed_rate_month_avg_diff\n",
      "\n",
      "------------------------------------------------------ Estimator: ------------------------------------------------------\n",
      "XGBRegressor\n",
      "\n",
      "------------------------------------------------- Params to be tested: -------------------------------------------------\n",
      "n_estimators [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
      "eta [0.01       0.05623413 0.31622777]\n",
      "max_depth [3, 6, 10]\n",
      "min_child_weight [1, 3, 6, 10]\n",
      "gamma [0, 1, 5, 10]\n",
      "\n",
      " # of possible combinations to be cross-validated: 1440\n",
      "\n",
      "Continue with this cv-params ? (y/n)  y\n",
      "\n",
      "---------------------------------- 5-folds Cross-validation starting for XGBRegressor-----------------------------------\n",
      " Fitting 5 folds for each of 1440 candidates, totalling 7200 fits \n",
      "\n",
      "-------------------------------------------------- Folder #1 starting --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a03f7860114470c9e0be5f3cfdd98bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1440.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------- Folder #2 starting --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b90df433f848fb907f9f0c650b79ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1440.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------- Folder #3 starting --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737ed85f008c49b9b13383d286668f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1440.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------- Folder #4 starting --------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bf0a92319741049641df45556d6cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1440.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dict = cv_model(X_train,\n",
    "                        Y_train,\n",
    "                        X_test,\n",
    "                        Y_test,\n",
    "                        predicted_feature=predicted_feature,\n",
    "                        estimator=estimator,\n",
    "                        params_to_cv=params_to_cv,  # dict\n",
    "                        n_splits_cv=5,\n",
    "                        plot_feature_importance=True,\n",
    "                        plot_model_perf=True,\n",
    "                        plot_reconstitution=True,\n",
    "                        reconstitution_feature='Fed_rate_month_avg',\n",
    "                        reconstitution_type_of_diff='diff'  # None or 'diff' or 'pct'                \n",
    "                       ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save cv and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import get_file_names, open_files, save_files\n",
    "\n",
    "file_name_struct = '{:s}_{:s}_score_{:.3f}'\n",
    "file_name = file_name_struct.format(str(estimator.__class__.__name__),\n",
    "                                  predicted_feature.replace(\"_\", \"\"),\n",
    "                                  model.score(X_test, Y_test[predicted_feature])\n",
    "                                 ).replace(\".\", \"\")\n",
    "\n",
    "save_files(path='Models/startdate_{:s}_testdate_{:s}/'.format(START_DATE.strftime(\"%Y\"),\n",
    "                                                             TEST_DATE.strftime(\"%Y\")\n",
    "                                                            ),\n",
    "           files={file_name + \".pkl\": results_dict[\"best_model_fitted\"]}\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_struct = 'cv_{:s}_{:s}'\n",
    "file_name = file_name_struct.format(str(estimator.__class__.__name__),\n",
    "                                    predicted_feature.replace(\"_\", \"\")\n",
    "                                   ).replace(\".\", \"\")\n",
    "save_files(path='Models/startdate_{:s}_testdate_{:s}/'.format(START_DATE.strftime(\"%Y\"),\n",
    "                                                             TEST_DATE.strftime(\"%Y\")\n",
    "                                                            ),\n",
    "           files={file_name + \".csv\": results_dict[results_cv]}\n",
    "          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfc8300634b1e462eaa0d9dbf574db025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
